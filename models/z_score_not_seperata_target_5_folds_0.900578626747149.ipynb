{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from tqdm import tqdm\n",
    "init_notebook_mode(connected=True)\n",
    "import math \n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "#import pandas_profiling\n",
    "\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:50].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('lgbm_importances01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "var_list = [f for f in train_df.columns if 'var' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_cols = [f +'_freq' for f in var_list]\n",
    "\n",
    "test_df[freq_cols] = test_df[var_list].apply(lambda x: x.map(x.value_counts()))\n",
    "train_df[freq_cols] = train_df[var_list].apply(lambda x: x.map(x.value_counts()))\n",
    "\n",
    "\n",
    "test_df['min_freq'] = test_df[freq_cols].min(1)\n",
    "train_df['min_freq'] = train_df[freq_cols].min(1)\n",
    "\n",
    "\n",
    "real_test = test_df.loc[test_df.min_freq==1].copy()\n",
    "fake_test = test_df.loc[test_df.min_freq!=1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df_1,train_df_2 = train_test_split(train_df, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "train_df_1[freq_cols] = train_df_1[var_list].apply(lambda x: x.map(x.value_counts()))\n",
    "train_df_2[freq_cols] = train_df_2[var_list].apply(lambda x: x.map(x.value_counts()))\n",
    "real_test[freq_cols] = real_test[var_list].apply(lambda x: x.map(x.value_counts()))\n",
    "fake_test[freq_cols] = fake_test[var_list].apply(lambda x: x.map(x.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df_1, train_df_2],sort=False)\n",
    "train_df.sort_index(inplace=True)\n",
    "\n",
    "test_df = pd.concat([real_test, fake_test],sort=False)\n",
    "test_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: z_score_not_seperata_target_5_folds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "n_folds = 5\n",
    "random_seed = 26\n",
    "model = 'z_score_not_seperata_target'\n",
    "\n",
    "\n",
    "model_name = \"{0}_{1}_folds\".format(model, n_folds)\n",
    "print(\"Model: {}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion = ['ID_code', 'target'] + freq_cols\n",
    "exclusion = ['ID_code', 'target'] \n",
    "\n",
    "# for var in tqdm(var_list):\n",
    "#     exclusion.append('frequency_{}'.format(var))\n",
    "#     exclusion.append('prob_{}'.format(var))\n",
    "#     exclusion.append('true_prob_{}'.format(var))\n",
    "    \n",
    "feats = [c for c in train_df.columns if c not in exclusion]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Fold: 1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.895254\tvalid_1's auc: 0.872088\n",
      "[1000]\ttraining's auc: 0.916909\tvalid_1's auc: 0.889843\n",
      "[1500]\ttraining's auc: 0.926544\tvalid_1's auc: 0.896048\n",
      "[2000]\ttraining's auc: 0.933294\tvalid_1's auc: 0.898689\n",
      "Early stopping, best iteration is:\n",
      "[2269]\ttraining's auc: 0.936681\tvalid_1's auc: 0.899329\n",
      "AUC = 0.8993286672443626\n",
      "Current Fold: 2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.895713\tvalid_1's auc: 0.871896\n",
      "[1000]\ttraining's auc: 0.916819\tvalid_1's auc: 0.889051\n",
      "[1500]\ttraining's auc: 0.926615\tvalid_1's auc: 0.895051\n",
      "[2000]\ttraining's auc: 0.933385\tvalid_1's auc: 0.897281\n",
      "Early stopping, best iteration is:\n",
      "[2092]\ttraining's auc: 0.934508\tvalid_1's auc: 0.897437\n",
      "AUC = 0.897436713765875\n",
      "Current Fold: 3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.89466\tvalid_1's auc: 0.878067\n",
      "[1000]\ttraining's auc: 0.91599\tvalid_1's auc: 0.893915\n",
      "[1500]\ttraining's auc: 0.92605\tvalid_1's auc: 0.899761\n",
      "Early stopping, best iteration is:\n",
      "[1909]\ttraining's auc: 0.931548\tvalid_1's auc: 0.901717\n",
      "AUC = 0.9017167428560366\n",
      "Current Fold: 4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.894644\tvalid_1's auc: 0.877622\n",
      "[1000]\ttraining's auc: 0.916613\tvalid_1's auc: 0.893983\n",
      "[1500]\ttraining's auc: 0.92634\tvalid_1's auc: 0.899748\n",
      "[2000]\ttraining's auc: 0.933045\tvalid_1's auc: 0.901783\n",
      "[2500]\ttraining's auc: 0.939297\tvalid_1's auc: 0.90258\n",
      "Early stopping, best iteration is:\n",
      "[2453]\ttraining's auc: 0.938758\tvalid_1's auc: 0.902693\n",
      "AUC = 0.9026927541647989\n",
      "Current Fold: 5\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's auc: 0.895169\tvalid_1's auc: 0.875022\n",
      "[1000]\ttraining's auc: 0.916208\tvalid_1's auc: 0.892602\n",
      "[1500]\ttraining's auc: 0.925821\tvalid_1's auc: 0.8985\n",
      "[2000]\ttraining's auc: 0.932757\tvalid_1's auc: 0.901484\n",
      "Early stopping, best iteration is:\n",
      "[2163]\ttraining's auc: 0.934872\tvalid_1's auc: 0.90197\n",
      "AUC = 0.9019704624268743\n",
      "Overall AUC = 0.900578626747149\n",
      "Saving submission file\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_seed)\n",
    "oof_preds = np.zeros((len(train_df), 1))\n",
    "test_preds = np.zeros((len(test_df), 1))\n",
    "\n",
    "\n",
    "X = train_df[feats]\n",
    "y = train_df['target']\n",
    "X_test = test_df[feats]\n",
    "test_ids = test_df.ID_code.values\n",
    "X['target'] = train_df['target']\n",
    "\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    #'scale_pos_weight': 400,\n",
    "    #'device' : 'gpu' ,\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 5, #31\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 10,\n",
    "    'learning_rate': 0.05, #0.05\n",
    "    'verbose': 30\n",
    "    #'min_data_in_leaf': 200\n",
    "}\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(X, y)):\n",
    "    print(\"Current Fold: {}\".format(fold_+1))\n",
    "    trn_x, trn_y = X.iloc[trn_, :], y[trn_]\n",
    "    val_x, val_y = X.iloc[val_, :], y[val_]\n",
    "    \n",
    "\n",
    "    z_pos_cols = []\n",
    "    z_neg_cols = []\n",
    "    z_diff_cols = []\n",
    "    for var in var_list:\n",
    "        \n",
    "        #pos\n",
    "        trn_x[f'z_{var}_pos'] = (trn_x[var] - trn_x.loc[trn_x.target==1, var].mean())/(trn_x.loc[trn_x.target==1, var].std()/(trn_x[f'{var}_freq'].apply(lambda x: math.sqrt(x))))\n",
    "        val_x[f'z_{var}_pos'] = (val_x[var] - trn_x.loc[trn_x.target==1, var].mean())/(trn_x.loc[trn_x.target==1, var].std()/(val_x[f'{var}_freq'].apply(lambda x: math.sqrt(x))))\n",
    "        X_test[f'z_{var}_pos'] = (X_test[var] - trn_x.loc[trn_x.target==1, var].mean())/(trn_x.loc[trn_x.target==1, var].std()/(X_test[f'{var}_freq'].apply(lambda x: math.sqrt(x))))\n",
    "\n",
    "        \n",
    "        trn_x[f'z_{var}_neg'] = (trn_x[var] - trn_x.loc[trn_x.target==0, var].mean())/(trn_x.loc[trn_x.target==0, var].std()/(trn_x[f'{var}_freq'].apply(lambda x: math.sqrt(x))))\n",
    "        val_x[f'z_{var}_neg'] = (val_x[var] - trn_x.loc[trn_x.target==0, var].mean())/(trn_x.loc[trn_x.target==0, var].std()/(val_x[f'{var}_freq'].apply(lambda x: math.sqrt(x))))\n",
    "        X_test[f'z_{var}_neg'] = (X_test[var] - trn_x.loc[trn_x.target==0, var].mean())/(trn_x.loc[trn_x.target==0, var].std()/(X_test[f'{var}_freq'].apply(lambda x: math.sqrt(x))))\n",
    "\n",
    "        \n",
    "        trn_x[f'z_{var}_where'] = np.where(abs(trn_x[f'z_{var}_pos']) > abs(trn_x[f'z_{var}_neg']),1,0)\n",
    "        val_x[f'z_{var}_where'] = np.where(abs(val_x[f'z_{var}_pos']) > abs(val_x[f'z_{var}_neg']),1,0)\n",
    "        X_test[f'z_{var}_where'] = np.where(abs(X_test[f'z_{var}_pos']) > abs(X_test[f'z_{var}_neg']),1,0)\n",
    "        \n",
    "        z_pos_cols.append(f'z_{var}_pos')\n",
    "        z_neg_cols.append(f'z_{var}_neg')\n",
    "        z_diff_cols.append(f'z_{var}_where')\n",
    "        \n",
    "\n",
    "    exclusion = ['ID_code', 'target'] + freq_cols\n",
    "\n",
    "    # for var in tqdm(var_list):\n",
    "    #     exclusion.append('frequency_{}'.format(var))\n",
    "    #     exclusion.append('prob_{}'.format(var))\n",
    "    #     exclusion.append('true_prob_{}'.format(var))\n",
    "\n",
    "    feats = [c for c in trn_x.columns if c not in exclusion]\n",
    "\n",
    "\n",
    "\n",
    "    trn_lgb = lgb.Dataset(trn_x[feats], trn_y)\n",
    "    val_lgb = lgb.Dataset(val_x[feats], val_y)\n",
    "    clf = lgb.train(parameters,\n",
    "                     train_set=trn_lgb,\n",
    "                     #valid_sets=[valid_data_lgb,holdout_data_lgb],\n",
    "                     valid_sets=[trn_lgb, val_lgb],\n",
    "                     num_boost_round=30000,\n",
    "                     early_stopping_rounds=50,\n",
    "                     verbose_eval=500)\n",
    "    \n",
    "\n",
    "\n",
    "    val_pred = clf.predict(val_x[feats])\n",
    "    test_fold_pred = clf.predict(X_test[feats])\n",
    "\n",
    "    print(\"AUC = {}\".format(roc_auc_score(val_y, val_pred)))\n",
    "    oof_preds[val_, :] = val_pred.reshape((-1, 1))\n",
    "    test_preds += test_fold_pred.reshape((-1, 1))\n",
    "    \n",
    "   # print('getting feature importance')\n",
    "    \n",
    "#     fold_importance_df = pd.DataFrame()\n",
    "#     fold_importance_df[\"feature\"] = feats\n",
    "#     fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "#     fold_importance_df[\"fold\"] = fold_ + 1\n",
    "#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    \n",
    "test_preds /= n_folds\n",
    "roc_score = roc_auc_score(y, oof_preds.ravel())\n",
    "print(\"Overall AUC = {}\".format(roc_score))\n",
    "\n",
    "\n",
    "print(\"Saving submission file\")\n",
    "sample = pd.read_csv('../data/sample_submission.csv')\n",
    "sample.target = test_preds.astype(float)\n",
    "sample.ID_code = test_ids\n",
    "sample.to_csv('../submissions/{}_{}.csv'.format(model_name,str(roc_score)), index=False)\n",
    "\n",
    "#display_importances(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
