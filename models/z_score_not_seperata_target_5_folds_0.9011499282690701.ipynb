{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from tqdm import tqdm\n",
    "init_notebook_mode(connected=True)\n",
    "import math \n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "#import pandas_profiling\n",
    "\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:50].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('lgbm_importances01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "var_list = [f for f in train_df.columns if 'var' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_cols = [f +'_freq' for f in var_list]\n",
    "\n",
    "test_df[freq_cols] = test_df[var_list].apply(lambda x: x.map(x.value_counts()))\n",
    "train_df[freq_cols] = train_df[var_list].apply(lambda x: x.map(x.value_counts()))\n",
    "\n",
    "\n",
    "test_df['min_freq'] = test_df[freq_cols].min(1)\n",
    "train_df['min_freq'] = train_df[freq_cols].min(1)\n",
    "\n",
    "\n",
    "real_test = test_df.loc[test_df.min_freq==1].copy()\n",
    "fake_test = test_df.loc[test_df.min_freq!=1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df_1,train_df_2 = train_test_split(train_df, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "train_df_1[freq_cols] = train_df_1[var_list].apply(lambda x: x.map(x.value_counts()))\n",
    "train_df_2[freq_cols] = train_df_2[var_list].apply(lambda x: x.map(x.value_counts()))\n",
    "real_test[freq_cols] = real_test[var_list].apply(lambda x: x.map(x.value_counts()))\n",
    "fake_test[freq_cols] = fake_test[var_list].apply(lambda x: x.map(x.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df_1, train_df_2],sort=False)\n",
    "train_df.sort_index(inplace=True)\n",
    "\n",
    "test_df = pd.concat([real_test, fake_test],sort=False)\n",
    "test_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: z_score_not_seperata_target_5_folds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "n_folds = 5\n",
    "random_seed = 26\n",
    "model = 'z_score_not_seperata_target'\n",
    "\n",
    "\n",
    "model_name = \"{0}_{1}_folds\".format(model, n_folds)\n",
    "print(\"Model: {}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion = ['ID_code', 'target'] + freq_cols\n",
    "exclusion = ['ID_code', 'target'] \n",
    "\n",
    "# for var in tqdm(var_list):\n",
    "#     exclusion.append('frequency_{}'.format(var))\n",
    "#     exclusion.append('prob_{}'.format(var))\n",
    "#     exclusion.append('true_prob_{}'.format(var))\n",
    "    \n",
    "feats = [c for c in train_df.columns if c not in exclusion]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Fold: 1\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[500]\ttraining's auc: 0.895374\tvalid_1's auc: 0.871961\n",
      "[1000]\ttraining's auc: 0.916737\tvalid_1's auc: 0.889489\n",
      "[1500]\ttraining's auc: 0.926364\tvalid_1's auc: 0.895714\n",
      "[2000]\ttraining's auc: 0.933314\tvalid_1's auc: 0.89828\n",
      "[2500]\ttraining's auc: 0.939434\tvalid_1's auc: 0.899092\n",
      "[3000]\ttraining's auc: 0.945308\tvalid_1's auc: 0.899575\n",
      "Early stopping, best iteration is:\n",
      "[2972]\ttraining's auc: 0.944956\tvalid_1's auc: 0.899648\n",
      "AUC = 0.8996475613649604\n",
      "Current Fold: 2\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[500]\ttraining's auc: 0.895466\tvalid_1's auc: 0.872886\n",
      "[1000]\ttraining's auc: 0.91668\tvalid_1's auc: 0.8899\n",
      "[1500]\ttraining's auc: 0.926525\tvalid_1's auc: 0.895534\n",
      "[2000]\ttraining's auc: 0.933484\tvalid_1's auc: 0.898145\n",
      "Early stopping, best iteration is:\n",
      "[2182]\ttraining's auc: 0.935597\tvalid_1's auc: 0.898497\n",
      "AUC = 0.8984968158291392\n",
      "Current Fold: 3\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[500]\ttraining's auc: 0.894115\tvalid_1's auc: 0.877748\n",
      "[1000]\ttraining's auc: 0.915818\tvalid_1's auc: 0.893795\n",
      "[1500]\ttraining's auc: 0.925847\tvalid_1's auc: 0.899502\n",
      "[2000]\ttraining's auc: 0.932638\tvalid_1's auc: 0.901952\n",
      "[2500]\ttraining's auc: 0.938746\tvalid_1's auc: 0.902928\n",
      "Early stopping, best iteration is:\n",
      "[2593]\ttraining's auc: 0.939801\tvalid_1's auc: 0.903219\n",
      "AUC = 0.9032189317448334\n",
      "Current Fold: 4\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[500]\ttraining's auc: 0.894137\tvalid_1's auc: 0.878096\n",
      "[1000]\ttraining's auc: 0.916259\tvalid_1's auc: 0.89413\n",
      "[1500]\ttraining's auc: 0.926091\tvalid_1's auc: 0.899987\n",
      "[2000]\ttraining's auc: 0.932692\tvalid_1's auc: 0.901967\n",
      "[2500]\ttraining's auc: 0.938905\tvalid_1's auc: 0.902532\n",
      "Early stopping, best iteration is:\n",
      "[2448]\ttraining's auc: 0.938291\tvalid_1's auc: 0.902651\n",
      "AUC = 0.9026507980920534\n",
      "Current Fold: 5\n",
      "Training until validation scores don't improve for 150 rounds.\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_seed)\n",
    "oof_preds = np.zeros((len(train_df), 1))\n",
    "test_preds = np.zeros((len(test_df), 1))\n",
    "\n",
    "\n",
    "X = train_df[feats]\n",
    "y = train_df['target']\n",
    "X_test = test_df[feats]\n",
    "test_ids = test_df.ID_code.values\n",
    "X['target'] = train_df['target']\n",
    "\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    #'scale_pos_weight': 400,\n",
    "    #'device' : 'gpu' ,\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 5, #31\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 10,\n",
    "    'learning_rate': 0.05, #0.05\n",
    "    'verbose': 30\n",
    "    #'min_data_in_leaf': 200\n",
    "}\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(X, y)):\n",
    "    print(\"Current Fold: {}\".format(fold_+1))\n",
    "    trn_x, trn_y = X.iloc[trn_, :], y[trn_]\n",
    "    val_x, val_y = X.iloc[val_, :], y[val_]\n",
    "    \n",
    "\n",
    "    z_pos_cols = []\n",
    "    z_neg_cols = []\n",
    "    z_diff_cols = []\n",
    "    for var in var_list:\n",
    "        \n",
    "        #pos\n",
    "        trn_x[f'z_{var}_pos'] = (trn_x[var] - trn_x.loc[trn_x.target==1, var].mean())/(trn_x.loc[trn_x.target==1, var].std()/(trn_x[f'{var}_freq'].apply(lambda x: math.sqrt(x))))\n",
    "        val_x[f'z_{var}_pos'] = (val_x[var] - trn_x.loc[trn_x.target==1, var].mean())/(trn_x.loc[trn_x.target==1, var].std()/(val_x[f'{var}_freq'].apply(lambda x: math.sqrt(x))))\n",
    "        X_test[f'z_{var}_pos'] = (X_test[var] - trn_x.loc[trn_x.target==1, var].mean())/(trn_x.loc[trn_x.target==1, var].std()/(X_test[f'{var}_freq'].apply(lambda x: math.sqrt(x))))\n",
    "\n",
    "        \n",
    "        trn_x[f'z_{var}_neg'] = (trn_x[var] - trn_x.loc[trn_x.target==0, var].mean())/(trn_x.loc[trn_x.target==0, var].std()/(trn_x[f'{var}_freq'].apply(lambda x: math.sqrt(x))))\n",
    "        val_x[f'z_{var}_neg'] = (val_x[var] - trn_x.loc[trn_x.target==0, var].mean())/(trn_x.loc[trn_x.target==0, var].std()/(val_x[f'{var}_freq'].apply(lambda x: math.sqrt(x))))\n",
    "        X_test[f'z_{var}_neg'] = (X_test[var] - trn_x.loc[trn_x.target==0, var].mean())/(trn_x.loc[trn_x.target==0, var].std()/(X_test[f'{var}_freq'].apply(lambda x: math.sqrt(x))))\n",
    "\n",
    "        \n",
    "        trn_x[f'z_{var}_where'] = np.where(abs(trn_x[f'z_{var}_pos']) > abs(trn_x[f'z_{var}_neg']),1,0)\n",
    "        val_x[f'z_{var}_where'] = np.where(abs(val_x[f'z_{var}_pos']) > abs(val_x[f'z_{var}_neg']),1,0)\n",
    "        X_test[f'z_{var}_where'] = np.where(abs(X_test[f'z_{var}_pos']) > abs(X_test[f'z_{var}_neg']),1,0)\n",
    "        \n",
    "        z_pos_cols.append(f'z_{var}_pos')\n",
    "        z_neg_cols.append(f'z_{var}_neg')\n",
    "        z_diff_cols.append(f'z_{var}_where')\n",
    "        \n",
    "\n",
    "    exclusion = ['ID_code', 'target'] + freq_cols + z_diff_cols\n",
    "\n",
    "    # for var in tqdm(var_list):\n",
    "    #     exclusion.append('frequency_{}'.format(var))\n",
    "    #     exclusion.append('prob_{}'.format(var))\n",
    "    #     exclusion.append('true_prob_{}'.format(var))\n",
    "\n",
    "    feats = [c for c in trn_x.columns if c not in exclusion]\n",
    "\n",
    "\n",
    "\n",
    "    trn_lgb = lgb.Dataset(trn_x[feats], trn_y)\n",
    "    val_lgb = lgb.Dataset(val_x[feats], val_y)\n",
    "    clf = lgb.train(parameters,\n",
    "                     train_set=trn_lgb,\n",
    "                     #valid_sets=[valid_data_lgb,holdout_data_lgb],\n",
    "                     valid_sets=[trn_lgb, val_lgb],\n",
    "                     num_boost_round=30000,\n",
    "                     early_stopping_rounds=150,\n",
    "                     verbose_eval=500)\n",
    "    \n",
    "\n",
    "\n",
    "    val_pred = clf.predict(val_x[feats])\n",
    "    test_fold_pred = clf.predict(X_test[feats])\n",
    "\n",
    "    print(\"AUC = {}\".format(roc_auc_score(val_y, val_pred)))\n",
    "    oof_preds[val_, :] = val_pred.reshape((-1, 1))\n",
    "    test_preds += test_fold_pred.reshape((-1, 1))\n",
    "    \n",
    "   # print('getting feature importance')\n",
    "    \n",
    "#     fold_importance_df = pd.DataFrame()\n",
    "#     fold_importance_df[\"feature\"] = feats\n",
    "#     fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "#     fold_importance_df[\"fold\"] = fold_ + 1\n",
    "#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    \n",
    "test_preds /= n_folds\n",
    "roc_score = roc_auc_score(y, oof_preds.ravel())\n",
    "print(\"Overall AUC = {}\".format(roc_score))\n",
    "\n",
    "\n",
    "print(\"Saving submission file\")\n",
    "sample = pd.read_csv('../data/sample_submission.csv')\n",
    "sample.target = test_preds.astype(float)\n",
    "sample.ID_code = test_ids\n",
    "sample.to_csv('../submissions/{}_{}.csv'.format(model_name,str(roc_score)), index=False)\n",
    "\n",
    "#display_importances(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var nb = IPython.notebook;\n",
       "var kernel = IPython.notebook.kernel;\n",
       "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
       "kernel.execute(command);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var nb = IPython.notebook;\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../models/z_score_not_seperata_target_5_folds_0.900578626747149.ipynb'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "shutil.copyfile(os.path.basename(NOTEBOOK_FULL_PATH), \n",
    "                             '../models/{}_{}.ipynb'.format(model_name, str(roc_score)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
